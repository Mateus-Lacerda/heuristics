{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3624d194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "\n",
    "def carregar_dados(filepath: str):\n",
    "    \"\"\"Carrega os dados do arquivo .mat e os retorna.\"\"\"\n",
    "    raw_data = scipy.io.loadmat(filepath)\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    data.update({\n",
    "        'X_cal': raw_data['inputCalibration'].copy(),\n",
    "        'y_cal': raw_data['targetCalibration'].ravel(),\n",
    "        'X_test': raw_data['inputTest'].copy(),\n",
    "        'y_test': raw_data['targetTest'].ravel(),\n",
    "        'X_val': raw_data['inputValidation'].copy(),\n",
    "    })\n",
    "\n",
    "    wavenumbers = raw_data['wl'].ravel()\n",
    "\n",
    "    # Converter wavenumbers de nm para cm-1\n",
    "    # wavenumbers = 10**7 / wavenumbers\n",
    "    data['wavenumbers'] = wavenumbers\n",
    "\n",
    "    print(\"Dados carregados com sucesso.\")\n",
    "    print(f\"  Calibração (X, y): {data['X_cal'].shape}, {data['y_cal'].shape}\")\n",
    "    print(f\"  Teste (X, y):      {data['X_test'].shape}, {data['y_test'].shape}\")\n",
    "    print(f\"  Validação (X):   {data['X_val'].shape}\")\n",
    "    print(f\"  Números de onda (cm-1): {data['wavenumbers'].shape}, de {data['wavenumbers'].min():.2f} a {data['wavenumbers'].max():.2f}\")\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09f86a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados carregados com sucesso.\n",
      "  Calibração (X, y): (89, 372), (89,)\n",
      "  Teste (X, y):      (72, 372), (72,)\n",
      "  Validação (X):   (67, 372)\n",
      "  Números de onda (cm-1): (372,), de 952.42 a 1309.33\n"
     ]
    }
   ],
   "source": [
    "mat_file_path = '2012/ShootOut2012MATLAB/ShootOut2012MATLAB.mat'\n",
    "\n",
    "\n",
    "dados = carregar_dados(mat_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2b3316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_cal = dados['X_cal']\n",
    "# y_cal = dados['y_cal']\n",
    "# x_test = dados['X_test']\n",
    "# y_test = dados['y_test']\n",
    "# x_val = dados['X_val']\n",
    "# wavenumbers = dados['wavenumbers']\n",
    "import pandas as pd\n",
    "\n",
    "x_cal = pd.DataFrame(dados['X_cal'], columns=[f'feature_{i}' for i in range(dados['X_cal'].shape[1])])\n",
    "y_cal = pd.Series(dados['y_cal'], name='target')\n",
    "x_test = pd.DataFrame(dados['X_test'], columns=[f'feature_{i}' for i in range(dados['X_test'].shape[1])])\n",
    "y_test = pd.Series(dados['y_test'], name='target')\n",
    "x_val = pd.DataFrame(dados['X_val'], columns=[f'feature_{i}' for i in range(dados['X_val'].shape[1])])\n",
    "wavenumbers = dados['wavenumbers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0934ce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from meta_heuristics_fs import AntColonyOptimizationFS\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\"\"\"\n",
    "Machine Learning Parameters\n",
    "columns_list : Column names present in x_train_dataframe and x_test which will be used as input list for searching best list of features.\n",
    "\n",
    "data_dict : X and Y training and test data provided in dictionary format. Below is example of 5 fold cross validation data with keys. {0:{'x_train':x_train_dataframe,'y_train':y_train_array,'x_test':x_test_dataframe,'y_test':y_test_array},\n",
    "1:{'x_train':x_train_dataframe,'y_train':y_train_array,'x_test':x_test_dataframe,'y_test':y_test_array},\n",
    "2:{'x_train':x_train_dataframe,'y_train':y_train_array,'x_test':x_test_dataframe,'y_test':y_test_array},\n",
    "3:{'x_train':x_train_dataframe,'y_train':y_train_array,'x_test':x_test_dataframe,'y_test':y_test_array},\n",
    "4:{'x_train':x_train_dataframe,'y_train':y_train_array,'x_test':x_test_dataframe,'y_test':y_test_array}}\n",
    "If you only have train and test data and do not wish to do cross validation, use above dictionary format, with only one key.\n",
    "\n",
    "use_validation_data : Whether you want to use validation data as a boolean True or False. Default value is True. If false, user need not provide x_validation_dataframe and y_validation_dataframe\n",
    "\n",
    "x_validation_dataframe : dataframe containing features of validatoin dataset\n",
    "\n",
    "y_validation_dataframe : dataframe containing dependent variable of validation dataset\n",
    "\n",
    "model : Model object. It should have .fit and .predict attribute\n",
    "\n",
    "cost_function_improvement : Objective is to whether increase or decrease the cost during subsequent iterations. For regression it should be 'decrease' and for classification it should be 'increase'\n",
    "\n",
    "cost_function : Cost function for finding cost between actual and predicted values, depending on regression or classification problem. cost function should accept 'actual' and 'predicted' as arrays and return cost for the both.\n",
    "\n",
    "average : Averaging to be used. This is useful for clasification metrics such as 'f1_score', 'jaccard_score', 'fbeta_score', 'precision_score', 'recall_score' and 'roc_auc_score' when dependent variable is multi-class\n",
    "\n",
    "Ant Colony Optimization Parameters\n",
    "iterations : Number of times ant colony optimization will search for solutions. Default is 100\n",
    "\n",
    "N_ants : Number of ants in each iteration. Default is 100.\n",
    "\n",
    "run_time : Number of minutes to run the algorithm. This is checked in between each iteration. At start of each generation it is checked if runtime has exceeded than alloted time.\n",
    "If case run time did exceeds provided limit, best result from iterations executed so far is given as output.\n",
    "Default is 2 hours. i.e. 120 minutes.\n",
    "\n",
    "evaporation_rate : Evaporation rate. Values are between 0 and 1. If it is too large, chances are higher to find global optima, but computationally expensive. If it is low, chances of finding global optima are less. Default is kept as 0.9\n",
    "\n",
    "Q : Pheromene update coefficient. Value between 0 and 1. It affects the convergence speed. If it is large, ACO will get stuck at local optima. Default is kept as 0.2\n",
    "\n",
    "Output\n",
    "best_columns : List object with list of column names which gives best performance for the model. These features can be used for training and saving models separately by the user.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def cost_function(actual, predicted):\n",
    "    \"\"\"Cost function to calculate mean squared error.\"\"\"\n",
    "    return ((actual - predicted) ** 2).mean()\n",
    "\n",
    "aco = AntColonyOptimizationFS(\n",
    "    columns_list=[f'feature_{i}' for i in range(x_cal.shape[1])],\n",
    "    data_dict={\n",
    "        0: {'x_train': x_cal, 'y_train': y_cal, 'x_test': x_test, 'y_test': y_test}\n",
    "    },\n",
    "    use_validation_data=False,\n",
    "    model=LinearRegression(),\n",
    "    cost_function_improvement='decrease',\n",
    "    cost_function=cost_function,\n",
    "    average=None,\n",
    "    iterations=100,\n",
    "    N_ants=1000,\n",
    "    run_time=1,  # in minutes\n",
    "    evaporation_rate=0.5,\n",
    "    Q=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "88dbe6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best combined performance on test and validation data for iteration 0: 0.4979209681054345\n",
      "Best combined performance on test and validation data for iteration 1: 0.433978420202741\n",
      "Best combined performance on test and validation data for iteration 2: 0.3178403922806912\n",
      "Best combined performance on test and validation data for iteration 3: 0.29458939216973196\n",
      "Best combined performance on test and validation data for iteration 4: 0.2753668901295895\n",
      "Best combined performance on test and validation data for iteration 5: 0.25207428037295165\n",
      "Best combined performance on test and validation data for iteration 6: 0.24498420117609557\n",
      "Best combined performance on test and validation data for iteration 7: 0.2400973556407217\n",
      "Best combined performance on test and validation data for iteration 8: 0.23506136576583814\n",
      "Best combined performance on test and validation data for iteration 9: 0.23060956982010428\n",
      "Best combined performance on test and validation data for iteration 10: 0.2296254075287146\n",
      "Best combined performance on test and validation data for iteration 11: 0.22853903409236473\n",
      "Best combined performance on test and validation data for iteration 12: 0.22646743745982578\n",
      "Best combined performance on test and validation data for iteration 13: 0.22572493171503336\n",
      "Best combined performance on test and validation data for iteration 14: 0.22572493171503336\n",
      "Best combined performance on test and validation data for iteration 15: 0.22572493171503336\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m features = \u001b[43maco\u001b[49m\u001b[43m.\u001b[49m\u001b[43mGetBestFeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Pessoal/hmm/pt1/meta_heuristics_fs.py:730\u001b[39m, in \u001b[36mAntColonyOptimizationFS.GetBestFeatures\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    728\u001b[39m     ant = Ant()\n\u001b[32m    729\u001b[39m     \u001b[38;5;66;03m# create the first initialization for ant\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m730\u001b[39m     ant = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_constructAntSolution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mant\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m.ants.append(ant)\n\u001b[32m    733\u001b[39m \u001b[38;5;66;03m##for the iteration, after all colony of ants have been created\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Pessoal/hmm/pt1/meta_heuristics_fs.py:630\u001b[39m, in \u001b[36mAntColonyOptimizationFS._constructAntSolution\u001b[39m\u001b[34m(self, ant)\u001b[39m\n\u001b[32m    628\u001b[39m     score = \u001b[32m0.5\u001b[39m\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m     score = \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_calculate_cost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_at_feature_subset\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    632\u001b[39m \u001b[38;5;66;03m# for the ant, assign score and feature indexes used.\u001b[39;00m\n\u001b[32m    633\u001b[39m ant.val = score\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Pessoal/hmm/pt1/meta_heuristics_fs.py:579\u001b[39m, in \u001b[36m_calculate_cost\u001b[39m\u001b[34m(self, current_at_feature_subset)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Pessoal/hmm/pt1/.venv/lib/python3.13/site-packages/sklearn/linear_model/_base.py:297\u001b[39m, in \u001b[36mLinearModel.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    284\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[33;03m    Predict using the linear model.\u001b[39;00m\n\u001b[32m    286\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    295\u001b[39m \u001b[33;03m        Returns predicted values.\u001b[39;00m\n\u001b[32m    296\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Pessoal/hmm/pt1/.venv/lib/python3.13/site-packages/sklearn/linear_model/_base.py:274\u001b[39m, in \u001b[36mLinearModel._decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m     X = validate_data(\u001b[38;5;28mself\u001b[39m, X, accept_sparse=[\u001b[33m\"\u001b[39m\u001b[33mcsr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcsc\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcoo\u001b[39m\u001b[33m\"\u001b[39m], reset=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    277\u001b[39m     coef_ = \u001b[38;5;28mself\u001b[39m.coef_\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Pessoal/hmm/pt1/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:1751\u001b[39m, in \u001b[36mcheck_is_fitted\u001b[39m\u001b[34m(estimator, attributes, msg, all_or_any)\u001b[39m\n\u001b[32m   1748\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m is not an estimator instance.\u001b[39m\u001b[33m\"\u001b[39m % (estimator))\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m tags = \u001b[43mget_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1753\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tags.requires_fit \u001b[38;5;129;01mand\u001b[39;00m attributes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1754\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Pessoal/hmm/pt1/.venv/lib/python3.13/site-packages/sklearn/utils/_tags.py:393\u001b[39m, in \u001b[36mget_tags\u001b[39m\u001b[34m(estimator)\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_tags\u001b[39m(estimator) -> Tags:\n\u001b[32m    368\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get estimator tags.\u001b[39;00m\n\u001b[32m    369\u001b[39m \n\u001b[32m    370\u001b[39m \u001b[33;03m    :class:`~sklearn.BaseEstimator` provides the estimator tags machinery.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    390\u001b[39m \u001b[33;03m        The estimator tags.\u001b[39;00m\n\u001b[32m    391\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m     tag_provider = \u001b[43m_find_tags_provider\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tag_provider == \u001b[33m\"\u001b[39m\u001b[33m__sklearn_tags__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    396\u001b[39m         \u001b[38;5;66;03m# TODO(1.7): turn the warning into an error\u001b[39;00m\n\u001b[32m    397\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Pessoal/hmm/pt1/.venv/lib/python3.13/site-packages/sklearn/utils/_tags.py:333\u001b[39m, in \u001b[36m_find_tags_provider\u001b[39m\u001b[34m(estimator, warn)\u001b[39m\n\u001b[32m    330\u001b[39m         tags_provider.append(\u001b[33m\"\u001b[39m\u001b[33m__sklearn_tags__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    331\u001b[39m     tags_mro[klass.\u001b[34m__name__\u001b[39m] = tags_provider\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m all_providers = \u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtags_mro\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m__sklearn_tags__\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m all_providers:\n\u001b[32m    335\u001b[39m     \u001b[38;5;66;03m# default on the old tags infrastructure\u001b[39;00m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m_get_tags\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "features = aco.GetBestFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97561815",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
